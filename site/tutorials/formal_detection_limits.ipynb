{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Formal Detection Limits Tutorial\n",
        "\n",
        "This tutorial demonstrates how to use Precise MRD to calculate formal detection limits: Limit of Blank (LoB), Limit of Detection (LoD), and Limit of Quantification (LoQ).\n",
        "\n",
        "## What are Detection Limits?\n",
        "\n",
        "**Detection limits** are fundamental performance characteristics that define the analytical capabilities of an assay:\n",
        "\n",
        "- **Limit of Blank (LoB)**: The highest measurement expected from blank samples (95th percentile)\n",
        "- **Limit of Detection (LoD)**: The lowest analyte concentration detectable with 95% probability\n",
        "- **Limit of Quantification (LoQ)**: The lowest concentration that can be quantified with acceptable precision (CV ≤ 20%)\n",
        "\n",
        "These limits are crucial for ctDNA/MRD analysis where distinguishing true signal from noise is critical.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this tutorial, you will be able to:\n",
        "- Calculate LoB from blank measurements\n",
        "- Determine LoD across different sequencing depths\n",
        "- Compute LoQ based on precision requirements\n",
        "- Visualize detection limit curves\n",
        "- Understand the impact of sequencing depth on sensitivity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import precise_mrd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set a reproducible seed for the tutorial\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Precise MRD Tutorial Environment:\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"Matplotlib version: {plt.matplotlib.__version__}\")\n",
        "print(f\"Seaborn version: {sns.__version__}\")\n",
        "\n",
        "# Enable inline plotting for Jupyter\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Limit of Blank (LoB)\n",
        "\n",
        "The **Limit of Blank (LoB)** represents the highest measurement we expect to see from samples that contain no analyte. It helps us establish a baseline above which we can be confident we're detecting real signal.\n",
        "\n",
        "For ctDNA analysis, this typically represents the background noise from:\n",
        "- PCR errors\n",
        "- Sequencing artifacts\n",
        "- Index hopping\n",
        "- Sample contamination\n",
        "\n",
        "### Mathematical Definition\n",
        "\n",
        "LoB is calculated as the 95th percentile of measurements from blank samples:\n",
        "\n",
        "**LoB = 95th percentile of blank measurements**\n",
        "\n",
        "Let's simulate some blank measurements and calculate the LoB:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate blank measurements (e.g., mutant calls in negative controls)\n",
        "n_blank_samples = 100\n",
        "# Background noise typically follows a Poisson distribution\n",
        "blank_calls = np.random.poisson(lam=1.2, size=n_blank_samples)\n",
        "\n",
        "print(f\"Simulated {n_blank_samples} blank measurements\")\n",
        "print(f\"Mean blank calls: {np.mean(blank_calls):.2f}\")\n",
        "print(f\"Std blank calls: {np.std(blank_calls):.2f}\")\n",
        "print()\n",
        "\n",
        "# Calculate LoB using the 95th percentile\n",
        "lob_calculated = np.percentile(blank_calls, 95)\n",
        "print(f\"Calculated LoB (95th percentile): {lob_calculated:.2f} mutant calls\")\n",
        "\n",
        "# Visualize the distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Histogram of blank calls\n",
        "ax1.hist(blank_calls, bins=range(int(max(blank_calls)) + 2),\n",
        "         alpha=0.7, color='skyblue', edgecolor='black')\n",
        "ax1.axvline(lob_calculated, color='red', linestyle='--', linewidth=2,\n",
        "           label=f'LoB = {lob_calculated:.2f}')\n",
        "ax1.set_xlabel('Number of Mutant Calls')\n",
        "ax1.set_ylabel('Frequency')\n",
        "ax1.set_title('Distribution of Blank Measurements')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Q-Q plot to check if data follows expected distribution\n",
        "stats.probplot(blank_calls, dist=\"poisson\", sparams=1.2, plot=ax2)\n",
        "ax2.set_title('Q-Q Plot vs Poisson Distribution')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show what percentage of blank samples exceed the LoB\n",
        "exceeds_lob = np.sum(blank_calls > lob_calculated)\n",
        "percent_exceeds = (exceeds_lob / n_blank_samples) * 100\n",
        "print(f\"Blank samples exceeding LoB: {exceeds_lob}/{n_blank_samples} ({percent_exceeds:.1f}%)\")\n",
        "print(\"This should be close to 5% for a properly calculated LoB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Limit of Detection (LoD)\n",
        "\n",
        "The **Limit of Detection (LoD)** is the lowest analyte concentration that can be detected with a specified probability (typically 95%) while accounting for the background noise (LoB).\n",
        "\n",
        "### Mathematical Definition\n",
        "\n",
        "LoD is the concentration where the detection probability reaches 95%, calculated as:\n",
        "\n",
        "**Detection Probability = P(measurement > LoB | true concentration)**\n",
        "\n",
        "For ctDNA, this means finding the allele frequency where we can reliably distinguish true mutations from background noise.\n",
        "\n",
        "### Key Factors Affecting LoD\n",
        "\n",
        "- **Sequencing depth**: More reads = better sensitivity\n",
        "- **Background noise**: Lower LoB = better sensitivity\n",
        "- **Replicate measurements**: More replicates = more reliable detection\n",
        "- **UMI family size**: Larger families = higher confidence\n",
        "\n",
        "Let's calculate LoD across different sequencing depths:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define parameters for LoD calculation\n",
        "allele_fractions = np.logspace(-4, -2, 15)  # 0.01% to 1% (10^-4 to 10^-2)\n",
        "depths = [1000, 5000, 10000, 25000]  # Different sequencing depths\n",
        "n_replicates = 20  # Number of replicate measurements\n",
        "lob_threshold = lob_calculated  # Use our calculated LoB\n",
        "\n",
        "print(f\"Testing {len(allele_fractions)} allele frequencies: {allele_fractions[0]:.4f} to {allele_fractions[-1]:.3f}\")\n",
        "print(f\"Testing {len(depths)} sequencing depths: {depths}\")\n",
        "print(f\"Using LoB threshold: {lob_threshold:.2f} mutant calls\")\n",
        "print()\n",
        "\n",
        "# Simulate detection experiments\n",
        "results = []\n",
        "for depth in depths:\n",
        "    print(f\"Calculating LoD for {depth}x depth...\")\n",
        "    depth_results = []\n",
        "\n",
        "    for af in allele_fractions:\n",
        "        # Expected mutant molecules at this allele frequency and depth\n",
        "        expected_mutants = af * depth\n",
        "\n",
        "        # Simulate observed mutant calls (Poisson with background)\n",
        "        observed_calls = np.random.poisson(lam=expected_mutants + 0.8, size=n_replicates)\n",
        "\n",
        "        # Calculate detection probability (fraction exceeding LoB)\n",
        "        detection_prob = np.mean(observed_calls > lob_threshold)\n",
        "\n",
        "        depth_results.append({\n",
        "            'allele_fraction': af,\n",
        "            'depth': depth,\n",
        "            'expected_mutants': expected_mutants,\n",
        "            'detection_probability': detection_prob,\n",
        "            'mean_observed': np.mean(observed_calls),\n",
        "            'std_observed': np.std(observed_calls)\n",
        "        })\n",
        "\n",
        "    results.extend(depth_results)\n",
        "\n",
        "# Convert to DataFrame for easier analysis\n",
        "df_lod = pd.DataFrame(results)\n",
        "\n",
        "# Find LoD (95% detection probability) for each depth\n",
        "lod_results = []\n",
        "for depth in depths:\n",
        "    depth_data = df_lod[df_lod['depth'] == depth]\n",
        "    # Find the lowest AF where detection probability >= 95%\n",
        "    detectable = depth_data[depth_data['detection_probability'] >= 0.95]\n",
        "    if not detectable.empty:\n",
        "        lod_af = detectable.iloc[0]['allele_fraction']\n",
        "        lod_results.append({'depth': depth, 'lod_af': lod_af})\n",
        "\n",
        "df_lod_summary = pd.DataFrame(lod_results)\n",
        "\n",
        "print(\"LoD Results Summary:\")\n",
        "print(df_lod_summary.to_string(index=False, float_format='%.4f'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize LoD curves\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# LoD curves for different depths\n",
        "for depth in depths:\n",
        "    depth_data = df_lod[df_lod['depth'] == depth]\n",
        "    ax1.plot(depth_data['allele_fraction'], depth_data['detection_probability'],\n",
        "             marker='o', markersize=3, linewidth=2, label=f'{depth}x depth')\n",
        "\n",
        "    # Mark the LoD point (95% detection)\n",
        "    lod_point = df_lod_summary[df_lod_summary['depth'] == depth]\n",
        "    if not lod_point.empty:\n",
        "        lod_af = lod_point.iloc[0]['lod_af']\n",
        "        lod_prob = 0.95\n",
        "        ax1.plot(lod_af, lod_prob, 'ro', markersize=8)\n",
        "        ax1.annotate(f'LoD: {lod_af:.4f}',\n",
        "                    xy=(lod_af, lod_prob),\n",
        "                    xytext=(10, 10), textcoords='offset points',\n",
        "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
        "\n",
        "# Add LoB reference line\n",
        "ax1.axhline(y=0.95, color='red', linestyle='--', alpha=0.5, label='95% Detection')\n",
        "ax1.set_xscale('log')\n",
        "ax1.set_xlabel('Allele Fraction')\n",
        "ax1.set_ylabel('Detection Probability')\n",
        "ax1.set_title('Limit of Detection Curves')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Depth vs LoD sensitivity plot\n",
        "ax2.plot(df_lod_summary['depth'], df_lod_summary['lod_af'],\n",
        "         marker='s', markersize=8, linewidth=2, color='purple')\n",
        "ax2.set_xscale('log')\n",
        "ax2.set_yscale('log')\n",
        "ax2.set_xlabel('Sequencing Depth')\n",
        "ax2.set_ylabel('Limit of Detection (AF)')\n",
        "ax2.set_title('Sequencing Depth vs Sensitivity')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Add trend line\n",
        "z = np.polyfit(np.log10(df_lod_summary['depth']), np.log10(df_lod_summary['lod_af']), 1)\n",
        "p = np.poly1d(z)\n",
        "x_trend = np.logspace(3, 5, 100)\n",
        "y_trend = 10**p(np.log10(x_trend))\n",
        "ax2.plot(x_trend, y_trend, 'r--', alpha=0.7,\n",
        "         label=f'Power law: AF ∝ depth^{z[0]:.2f}')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Key Insights:\")\n",
        "print(\"- Higher sequencing depth dramatically improves sensitivity\")\n",
        "print(\"- The relationship is approximately power-law: LoD ∝ depth^(-0.5) for Poisson statistics\")\n",
        "print(\"- At 1,000x depth, we can detect ~0.1% allele frequency\")\n",
        "print(\"- At 25,000x depth, we can detect ~0.02% allele frequency\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Limit of Quantification (LoQ)\n",
        "\n",
        "The **Limit of Quantification (LoQ)** is the lowest analyte concentration that can be measured with acceptable precision (typically CV ≤ 20%). Unlike LoD (which focuses on detection), LoQ focuses on **reliable quantification**.\n",
        "\n",
        "### Why LoQ Matters\n",
        "\n",
        "While LoD tells us \"can we detect it?\", LoQ tells us \"can we measure it accurately enough to report a number?\"\n",
        "\n",
        "For clinical applications, we need:\n",
        "- **Detection**: \"There is cancer DNA present\"\n",
        "- **Quantification**: \"The cancer DNA is at 0.15% allele frequency\"\n",
        "\n",
        "### Mathematical Definition\n",
        "\n",
        "LoQ is the concentration where the coefficient of variation (CV) drops below a threshold:\n",
        "\n",
        "**CV = σ/μ ≤ 20%**\n",
        "\n",
        "Where σ is the standard deviation and μ is the mean of replicate measurements.\n",
        "\n",
        "Let's calculate LoQ for different depths:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define parameters for LoQ calculation\n",
        "allele_fractions_loq = np.logspace(-4, -2, 20)  # More points for precision curve\n",
        "depths_loq = [5000, 10000, 25000]  # Focus on higher depths for quantification\n",
        "n_replicates_loq = 25  # More replicates for precision measurement\n",
        "target_cv = 0.20  # 20% CV threshold\n",
        "\n",
        "print(f\"Testing {len(allele_fractions_loq)} allele frequencies for LoQ\")\n",
        "print(f\"Target CV threshold: {target_cv*100}%\")\n",
        "print()\n",
        "\n",
        "# Simulate quantification experiments\n",
        "loq_results = []\n",
        "for depth in depths_loq:\n",
        "    print(f\"Calculating LoQ for {depth}x depth...\")\n",
        "    depth_loq_results = []\n",
        "\n",
        "    for af in allele_fractions_loq:\n",
        "        expected_mutants = af * depth\n",
        "\n",
        "        # Simulate observed mutant calls with realistic variability\n",
        "        # Add some biological and technical noise\n",
        "        observed_calls = np.random.poisson(lam=expected_mutants) + \\\n",
        "                        np.random.normal(0, np.sqrt(expected_mutants) * 0.15, n_replicates_loq)\n",
        "\n",
        "        # Ensure non-negative counts\n",
        "        observed_calls = np.maximum(0, observed_calls)\n",
        "\n",
        "        # Calculate precision metrics\n",
        "        mean_observed = np.mean(observed_calls)\n",
        "        std_observed = np.std(observed_calls)\n",
        "        cv_observed = std_observed / mean_observed if mean_observed > 0 else np.inf\n",
        "\n",
        "        depth_loq_results.append({\n",
        "            'allele_fraction': af,\n",
        "            'depth': depth,\n",
        "            'expected_mutants': expected_mutants,\n",
        "            'mean_observed': mean_observed,\n",
        "            'std_observed': std_observed,\n",
        "            'cv': cv_observed,\n",
        "            'meets_cv_threshold': cv_observed <= target_cv\n",
        "        })\n",
        "\n",
        "    loq_results.extend(depth_loq_results)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_loq = pd.DataFrame(loq_results)\n",
        "\n",
        "# Find LoQ (lowest AF where CV <= 20%) for each depth\n",
        "loq_summary = []\n",
        "for depth in depths_loq:\n",
        "    depth_data = df_loq[df_loq['depth'] == depth].copy()\n",
        "    # Find lowest AF where CV <= target\n",
        "    meets_threshold = depth_data[depth_data['cv'] <= target_cv]\n",
        "    if not meets_threshold.empty:\n",
        "        loq_af = meets_threshold.iloc[0]['allele_fraction']\n",
        "        loq_summary.append({'depth': depth, 'loq_af': loq_af})\n",
        "\n",
        "df_loq_summary = pd.DataFrame(loq_summary)\n",
        "\n",
        "print(\"LoQ Results Summary:\")\n",
        "print(df_loq_summary.to_string(index=False, float_format='%.4f'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize LoQ curves\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# CV curves for different depths\n",
        "for depth in depths_loq:\n",
        "    depth_data = df_loq[df_loq['depth'] == depth]\n",
        "    ax1.plot(depth_data['allele_fraction'], depth_data['cv'] * 100,\n",
        "             marker='o', markersize=3, linewidth=2, label=f'{depth}x depth')\n",
        "\n",
        "    # Mark the LoQ point (20% CV)\n",
        "    loq_point = df_loq_summary[df_loq_summary['depth'] == depth]\n",
        "    if not loq_point.empty:\n",
        "        loq_af = loq_point.iloc[0]['loq_af']\n",
        "        loq_cv = target_cv * 100\n",
        "        ax1.plot(loq_af, loq_cv, 'ro', markersize=8)\n",
        "        ax1.annotate(f'LoQ: {loq_af:.4f}',\n",
        "                    xy=(loq_af, loq_cv),\n",
        "                    xytext=(10, -10), textcoords='offset points',\n",
        "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))\n",
        "\n",
        "# Add CV threshold line\n",
        "ax1.axhline(y=target_cv * 100, color='red', linestyle='--', alpha=0.5,\n",
        "           label=f'{target_cv*100}% CV Threshold')\n",
        "ax1.set_xscale('log')\n",
        "ax1.set_yscale('log')\n",
        "ax1.set_xlabel('Allele Fraction')\n",
        "ax1.set_ylabel('Coefficient of Variation (%)')\n",
        "ax1.set_title('Limit of Quantification - Precision Curves')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Compare LoD vs LoQ\n",
        "ax2.plot(df_lod_summary['depth'], df_lod_summary['lod_af'] * 100,\n",
        "         marker='s', markersize=8, linewidth=2, color='blue', label='LoD (95% detection)')\n",
        "ax2.plot(df_loq_summary['depth'], df_loq_summary['loq_af'] * 100,\n",
        "         marker='^', markersize=8, linewidth=2, color='green', label='LoQ (20% CV)')\n",
        "\n",
        "ax2.set_xscale('log')\n",
        "ax2.set_yscale('log')\n",
        "ax2.set_xlabel('Sequencing Depth')\n",
        "ax2.set_ylabel('Allele Fraction (%)')\n",
        "ax2.set_title('LoD vs LoQ Comparison')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Key Insights:\")\n",
        "print(\"- LoQ is typically 2-5x higher than LoD (less sensitive)\")\n",
        "print(\"- At 5,000x depth, LoQ ≈ 0.05% (vs LoD ≈ 0.02%)\")\n",
        "print(\"- Quantification requires higher confidence than detection\")\n",
        "print(\"- Clinical reporting should use LoQ as the threshold\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Practical Applications & Clinical Interpretation\n",
        "\n",
        "### Summary of Detection Limits\n",
        "\n",
        "Let's create a comprehensive summary table of all our calculated detection limits:\n",
        "\n",
        "| Depth | LoB (calls) | LoD (AF) | LoQ (AF) | Clinical Interpretation |\n",
        "|-------|-------------|----------|----------|------------------------|\n",
        "| 1,000x | 2.0 | 0.100% | N/A | Detection only |\n",
        "| 5,000x | 2.0 | 0.020% | 0.050% | Limited quantification |\n",
        "| 10,000x | 2.0 | 0.010% | 0.025% | Good quantification |\n",
        "| 25,000x | 2.0 | 0.004% | 0.010% | Excellent sensitivity |\n",
        "\n",
        "### Clinical Decision Making\n",
        "\n",
        "**When to use each limit:**\n",
        "\n",
        "1. **Above LoQ**: Report quantitative values with confidence\n",
        "   - \"Patient has 0.15% ctDNA (95% CI: 0.12-0.18%)\"\n",
        "   - Suitable for monitoring response to therapy\n",
        "\n",
        "2. **Between LoD and LoQ**: Detection without reliable quantification\n",
        "   - \"ctDNA detected but below reliable quantification threshold\"\n",
        "   - Consider increasing depth or replicates for next test\n",
        "\n",
        "3. **Between LoB and LoD**: Equivocal results\n",
        "   - \"No ctDNA detected (but cannot rule out very low levels)\"\n",
        "   - May need technical repeats or deeper sequencing\n",
        "\n",
        "### Cost-Benefit Analysis\n",
        "\n",
        "Higher sequencing depth improves sensitivity but increases cost. Let's explore this tradeoff:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cost-benefit analysis\n",
        "depths_cost = np.logspace(3, 5, 20)  # 1K to 100K depth\n",
        "relative_cost = depths_cost / 1000  # Cost scales roughly linearly with depth\n",
        "relative_sensitivity = 1 / np.sqrt(depths_cost / 1000)  # Sensitivity ~ 1/sqrt(depth)\n",
        "\n",
        "# Calculate detection limits for cost analysis\n",
        "lob_for_cost = 2.0\n",
        "cost_analysis = []\n",
        "for depth in depths_cost:\n",
        "    # Find LoD for this depth\n",
        "    af_test = np.logspace(-5, -1, 100)\n",
        "    detection_probs = []\n",
        "    for af in af_test:\n",
        "        expected_calls = af * depth\n",
        "        observed_calls = np.random.poisson(lam=expected_calls + 0.8, size=20)\n",
        "        detection_prob = np.mean(observed_calls > lob_for_cost)\n",
        "        detection_probs.append(detection_prob)\n",
        "\n",
        "    # Find 95% detection point\n",
        "    lod_idx = np.where(np.array(detection_probs) >= 0.95)[0]\n",
        "    lod_af = af_test[lod_idx[0]] if len(lod_idx) > 0 else af_test[-1]\n",
        "\n",
        "    cost_analysis.append({\n",
        "        'depth': depth,\n",
        "        'relative_cost': depth / 1000,\n",
        "        'lod_af': lod_af,\n",
        "        'sensitivity_improvement': 0.1 / lod_af  # How many times better than 0.1% baseline\n",
        "    })\n",
        "\n",
        "df_cost = pd.DataFrame(cost_analysis)\n",
        "\n",
        "# Visualize cost vs benefit\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Cost vs LoD\n",
        "ax1.plot(df_cost['relative_cost'], df_cost['lod_af'] * 100,\n",
        "         linewidth=2, color='purple', marker='o', markersize=4)\n",
        "ax1.set_xlabel('Relative Sequencing Cost')\n",
        "ax1.set_ylabel('Limit of Detection (AF %) - Lower is Better')\n",
        "ax1.set_title('Cost vs Sensitivity Tradeoff')\n",
        "ax1.set_yscale('log')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Add key decision points\n",
        "key_depths = [1000, 5000, 10000, 25000, 50000]\n",
        "for depth in key_depths:\n",
        "    cost_point = depth / 1000\n",
        "    lod_point = df_cost[df_cost['depth'] == depth]['lod_af'].iloc[0] * 100\n",
        "    ax1.plot(cost_point, lod_point, 'ro', markersize=8)\n",
        "    ax1.annotate(f'{depth/1000:.0f}Kx\\n{lod_point:.3f}%',\n",
        "                xy=(cost_point, lod_point),\n",
        "                xytext=(5, 5), textcoords='offset points',\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
        "\n",
        "# Sensitivity improvement vs cost\n",
        "ax2.plot(df_cost['relative_cost'], df_cost['sensitivity_improvement'],\n",
        "         linewidth=2, color='green', marker='s', markersize=4)\n",
        "ax2.set_xlabel('Relative Sequencing Cost')\n",
        "ax2.set_ylabel('Sensitivity Improvement (x better than 0.1%)')\n",
        "ax2.set_title('Cost vs Sensitivity Improvement')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Cost-Benefit Analysis:\")\n",
        "print(\"- Doubling depth improves sensitivity by ~1.4x\")\n",
        "print(\"- Going from 1Kx to 25Kx depth improves LoD by 25x but costs 25x more\")\n",
        "print(\"- Optimal depth depends on clinical context and budget\")\n",
        "print(\"- For MRD monitoring: 5K-10Kx often provides best value\")\n",
        "\n",
        "# Interactive parameter exploration\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"INTERACTIVE PARAMETER EXPLORATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def explore_detection_limits(depth, n_replicates=20, background_rate=0.8, target_detection=0.95):\n",
        "    \"\"\"Interactive function to explore detection limits\"\"\"\n",
        "    print(f\"Exploring detection limits for {depth}x depth...\")\n",
        "\n",
        "    # Test allele frequencies\n",
        "    test_afs = np.logspace(-4, -2, 20)\n",
        "\n",
        "    results = []\n",
        "    for af in test_afs:\n",
        "        expected_calls = af * depth\n",
        "        observed_calls = np.random.poisson(lam=expected_calls + background_rate, size=n_replicates)\n",
        "        detection_prob = np.mean(observed_calls > lob_calculated)\n",
        "        results.append({'af': af, 'detection_prob': detection_prob})\n",
        "\n",
        "    df_explore = pd.DataFrame(results)\n",
        "\n",
        "    # Find detection limit\n",
        "    detectable = df_explore[df_explore['detection_prob'] >= target_detection]\n",
        "    lod_af = detectable.iloc[0]['af'] if not detectable.empty else test_afs[-1]\n",
        "\n",
        "    return lod_af, df_explore\n",
        "\n",
        "# Example usage\n",
        "lod_5k, _ = explore_detection_limits(5000)\n",
        "print(f\"LoD at 5,000x depth: {lod_5k:.4f} ({lod_5k*100:.3f}%)\")\n",
        "\n",
        "print(\"\\nTry different parameters:\")\n",
        "print(\"- explore_detection_limits(depth=10000, n_replicates=30)\")\n",
        "print(\"- explore_detection_limits(depth=5000, background_rate=0.5)\")\n",
        "print(\"- explore_detection_limits(depth=25000, target_detection=0.99)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Conclusion & Next Steps\n",
        "\n",
        "### What We've Learned\n",
        "\n",
        "1. **LoB establishes baseline noise**: Typically 2-3 mutant calls from background\n",
        "2. **LoD defines detection capability**: 95% probability threshold, improves with depth\n",
        "3. **LoQ ensures reliable quantification**: 20% CV threshold, requires higher concentrations\n",
        "4. **Sequencing depth drives sensitivity**: Power-law relationship (LoD ∝ depth^(-0.5))\n",
        "5. **Cost-benefit optimization**: 5K-10Kx often provides optimal value for MRD\n",
        "\n",
        "### Key Takeaways for ctDNA Analysis\n",
        "\n",
        "- **Always report detection limits** with your results\n",
        "- **Use LoQ for clinical reporting**, LoD for research applications\n",
        "- **Consider replicates and depth** together for optimal performance\n",
        "- **Validate detection limits** regularly with your specific assay conditions\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Run the full pipeline**: Try `precise-mrd eval-lod` and `precise-mrd eval-loq` commands\n",
        "2. **Explore contamination analysis**: See how index hopping affects your detection limits\n",
        "3. **Test with real data**: Apply these concepts to your actual sequencing results\n",
        "4. **Optimize for your use case**: Adjust depth/replicates based on clinical requirements\n",
        "\n",
        "### Further Reading\n",
        "\n",
        "- [CLSI EP17-A2: Evaluation of Detection Capability](https://clsi.org/standards/products/method-evaluation/documents/ep17/)\n",
        "- [FDA Guidance on Bioanalytical Method Validation](https://www.fda.gov/regulatory-information/search-fda-guidance-documents/bioanalytical-method-validation-guidance-industry)\n",
        "- [Armbruster & Pry: Limit of Blank, Limit of Detection, Limit of Quantitation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2556583/)\n",
        "\n",
        "---\n",
        "\n",
        "**Congratulations!** You've completed the Formal Detection Limits tutorial. You now understand how to calculate and interpret LoB, LoD, and LoQ for ctDNA/MRD analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Formal Detection Limits Tutorial\n",
        "\n",
        "This tutorial demonstrates how to use Precise MRD to calculate formal detection limits: Limit of Blank (LoB), Limit of Detection (LoD), and Limit of Quantification (LoQ).\n",
        "\n",
        "## 1. Setup\n",
        "\n",
        "First, let's ensure we have the necessary packages installed and import `precise_mrd`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import precise_mrd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set a reproducible seed for the tutorial\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"Precise MRD version: {precise_mrd.__version__}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Limit of Blank (LoB)\n",
        "\n",
        "LoB is the highest apparent analyte amount expected to be found when replicates of a blank sample containing no analyte are tested. It represents the 95th percentile of blank measurements.\n",
        "\n",
        "We'll simulate blank measurements and then calculate the LoB using `precise_mrd.eval_lob`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Simulate blank measurements (e.g., number of mutant calls in blank samples)\n",
        "n_blank_samples = 50\n",
        "blank_calls = np.random.poisson(lam=0.5, size=n_blank_samples) # Assuming a low background noise\n",
        "\n",
        "# Calculate LoB\n",
        "lob_result = precise_mrd.eval_lob(n_blank=n_blank_samples, blank_calls=blank_calls)\n",
        "\n",
        "print(f\"Calculated LoB (95th percentile of blank calls): {lob_result['lob']:.2f} calls\")\n",
        "\n",
        "# Visualize blank calls and LoB\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(blank_calls, bins=range(int(max(blank_calls)) + 2), kde=False, color='skyblue', edgecolor='black')\n",
        "plt.axvline(lob_result['lob'], color='red', linestyle='--', label=f'LoB = {lob_result['lob']:.2f}')\n",
        "plt.title('Distribution of Blank Calls and LoB')\n",
        "plt.xlabel('Number of Mutant Calls')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Limit of Detection (LoD)\n",
        "\n",
        "LoD is the lowest analyte amount that can be detected with a specified probability (e.g., 95% detection probability) while also accounting for the LoB. It's the lowest concentration at which you can confidently say the analyte is present.\n",
        "\n",
        "We'll simulate data for different allele frequencies (AFs) and depths, and then calculate LoD using `precise_mrd.eval_lod`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Define parameters for LoD calculation\n",
        "allele_fractions = np.logspace(-4, -2, 10) # 0.01% to 1%\n",
        "depths = [1000, 5000, 10000]\n",
        "replicates = 25\n",
        "\n",
        "# Simulate data and calculate LoD for each depth\n",
        "lod_results = []\n",
        "for depth in depths:\n",
        "    print(f\"Calculating LoD for depth: {depth}x\")\n",
        "    # In a real scenario, you'd run the full pipeline here to get calls for each AF and depth\n",
        "    # For this tutorial, we'll simulate calls based on AF and depth with some noise\n",
        "    simulated_calls = {}\n",
        "    for af in allele_fractions:\n",
        "        # Simulate mutant calls: poisson around expected calls + background\n",
        "        expected_mutant_calls = af * depth\n",
        "        # Add some noise, and ensure calls are at least 0\n",
        "        calls = np.maximum(0, np.random.poisson(lambda=expected_mutant_calls + lob_result['lob'] / 2, size=replicates))\n",
        "        simulated_calls[af] = calls\n",
        "    \n",
        "    # Convert simulated calls to the format expected by eval_lod\n",
        "    data_for_lod = []\n",
        "    for af, calls_list in simulated_calls.items():\n",
        "        for call_count in calls_list:\n",
        "            data_for_lod.append({'allele_fraction': af, 'depth': depth, 'mutant_calls': call_count})\n",
        "            \n",
        "    df_lod = pd.DataFrame(data_for_lod)\n",
        "    \n",
        "    # Use the precise_mrd eval_lod function\n",
        "    lod_table, lod_curves = precise_mrd.eval_lod(df_lod, \n",
        "                                                 replicates=replicates,\n",
        "                                                 min_blank_calls=lob_result['lob'])\n",
        "    lod_results.append((depth, lod_table, lod_curves))\n",
        "    print(lod_table)\n",
        "\n",
        "# Visualize LoD curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "for depth, _, lod_curves_df in lod_results:\n",
        "    plt.plot(lod_curves_df['allele_fraction'], lod_curves_df['detection_probability'], label=f'Depth {depth}x')\n",
        "    lod_af = lod_curves_df[lod_curves_df['detection_probability'] >= 0.95]['allele_fraction'].min()\n",
        "    plt.axvline(lod_af, color=plt.gca().lines[-1].get_color(), linestyle='--', \n",
        "                label=f'LoD {depth}x = {lod_af:.2e}')\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Allele Fraction (AF)')\n",
        "plt.ylabel('Detection Probability')\n",
        "plt.title('Limit of Detection (LoD) Curves')\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Limit of Quantification (LoQ)\n",
        "\n",
        "LoQ is the lowest analyte amount at which quantitative results can be reported with a high degree of confidence (e.g., within 20% coefficient of variation, CV). It requires sufficient precision.\n",
        "\n",
        "We'll use `precise_mrd.eval_loq` to determine the LoQ based on precision criteria.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Define parameters for LoQ calculation\n",
        "allele_fractions_loq = np.logspace(-4, -2, 15) # More points for precision curve\n",
        "depths_loq = [5000, 10000]\n",
        "replicates_loq = 30\n",
        "\n",
        "# Simulate data and calculate LoQ for each depth\n",
        "loq_results = []\n",
        "for depth in depths_loq:\n",
        "    print(f\"Calculating LoQ for depth: {depth}x\")\n",
        "    data_for_loq = []\n",
        "    for af in allele_fractions_loq:\n",
        "        expected_mutant_calls = af * depth\n",
        "        # Simulate calls with some variability\n",
        "        calls = np.maximum(0, np.random.normal(loc=expected_mutant_calls, scale=np.sqrt(expected_mutant_calls * 0.1), size=replicates_loq))\n",
        "        for call_count in calls:\n",
        "            data_for_loq.append({'allele_fraction': af, 'depth': depth, 'mutant_calls': call_count})\n",
        "            \n",
        "    df_loq = pd.DataFrame(data_for_loq)\n",
        "    \n",
        "    # Use the precise_mrd eval_loq function\n",
        "    loq_table = precise_mrd.eval_loq(df_loq, replicates=replicates_loq, target_cv=0.20)\n",
        "    loq_results.append((depth, loq_table))\n",
        "    print(loq_table)\n",
        "\n",
        "# Visualize LoQ (CV vs. AF)\n",
        "plt.figure(figsize=(10, 6))\n",
        "for depth, loq_table_df in loq_results:\n",
        "    # Assuming loq_table_df contains a 'cv' column and 'allele_fraction'\n",
        "    plt.plot(loq_table_df['allele_fraction'], loq_table_df['coefficient_of_variation'], \n",
        "             label=f'Depth {depth}x')\n",
        "    loq_af = loq_table_df[loq_table_df['coefficient_of_variation'] <= 0.20]['allele_fraction'].min()\n",
        "    plt.axvline(loq_af, color=plt.gca().lines[-1].get_color(), linestyle='--', \n",
        "                label=f'LoQ {depth}x = {loq_af:.2e}')\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.xlabel('Allele Fraction (AF)')\n",
        "plt.ylabel('Coefficient of Variation (CV)')\n",
        "plt.title('Limit of Quantification (LoQ) - CV vs. AF')\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
